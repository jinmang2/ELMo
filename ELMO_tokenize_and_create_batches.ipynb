{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo Char-CNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# *~ coding convention ~*\n",
    "from overrides import overrides\n",
    "from typing import Callable\n",
    "\n",
    "# Python Standard Library\n",
    "import collections\n",
    "import logging\n",
    "import random\n",
    "import codecs\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Python Installed Library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuction: dict to namedtuple\n",
    "def dict2namedtuple(dic):\n",
    "    return collections.namedtuple('Namespace', dic.keys())(**dic)\n",
    "\n",
    "# input your directories path\n",
    "model_dir = 'C:/workspace/ELMo/161/'\n",
    "args2 = dict2namedtuple(\n",
    "    json.load(\n",
    "        codecs.open(\n",
    "            os.path.join(model_dir, 'config.json'), \n",
    "            'r', encoding='utf-8')\n",
    "    )\n",
    ")\n",
    "\n",
    "# args2.config_path == 'cnn_50_100_512_4096_sample.json'\n",
    "\n",
    "# load config\n",
    "with open(os.path.join(model_dir, args2.config_path), 'r') as fin:\n",
    "    config = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder': {'name': 'elmo',\n",
       "  'projection_dim': 512,\n",
       "  'cell_clip': 3,\n",
       "  'proj_clip': 3,\n",
       "  'dim': 4096,\n",
       "  'n_layers': 2},\n",
       " 'token_embedder': {'name': 'cnn',\n",
       "  'activation': 'relu',\n",
       "  'filters': [[1, 32],\n",
       "   [2, 32],\n",
       "   [3, 64],\n",
       "   [4, 128],\n",
       "   [5, 256],\n",
       "   [6, 512],\n",
       "   [7, 1024]],\n",
       "  'n_highway': 2,\n",
       "  'word_dim': 100,\n",
       "  'char_dim': 50,\n",
       "  'max_characters_per_token': 50},\n",
       " 'classifier': {'name': 'sampled_softmax', 'n_samples': 8192},\n",
       " 'dropout': 0.1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Inputs\n",
    "sents = [['발', '없는', '말이', '천리', '간다'],\n",
    "         ['다시', '사랑한다', '말', '할까'],\n",
    "         ['유독', '너와', '헤어지다', '싫다', '밤', '집', '으로', '돌아가다']]\n",
    "\n",
    "# Set maximum number of characters\n",
    "max_chars = 98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, textset = [], []\n",
    "for sent in sents:\n",
    "    # Add begin of sentence(bos)\n",
    "    data = ['<bos>']\n",
    "    text = []\n",
    "    for token in sent:\n",
    "        text.append(token)\n",
    "        # ELMo's input is character\n",
    "        # Since ElMo uses char-CNN, input_dim must be SAME\n",
    "        # if numChars+2 < max_chars: why +2? bos & eos\n",
    "        #     pad values to pad_id\n",
    "        # else:\n",
    "        #     cut token:= token[:max_chars - 2]\n",
    "        if max_chars is not None and len(token) + 2 > max_chars:\n",
    "            token = token[:max_chars - 2]\n",
    "        data.append(token)\n",
    "    # Add end of sentence(eos)\n",
    "    data.append('<eos>')\n",
    "    dataset.append(data)\n",
    "    textset.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<bos>', '발', '없는', '말이', '천리', '간다', '<eos>'],\n",
       " ['<bos>', '다시', '사랑한다', '말', '할까', '<eos>'],\n",
       " ['<bos>', '유독', '너와', '헤어지다', '싫다', '밤', '집', '으로', '돌아가다', '<eos>']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['발', '없는', '말이', '천리', '간다'],\n",
       " ['다시', '사랑한다', '말', '할까'],\n",
       " ['유독', '너와', '헤어지다', '싫다', '밤', '집', '으로', '돌아가다']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If GPU is available, use_cuda:= True\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    EmbeddingLayer\n",
    "    \n",
    "    두 가지 역할을 수행\n",
    "    1. word/character를 사전 규칙에 따라 index로 변환\n",
    "    2. config['token_embedder']['char_dim']으로 차원을 축소\n",
    "    \"\"\"\n",
    "    def __init__(self, n_d, word2id, embs=None, fix_emb=True, oov='<oov>', pad='<pad>', normalize=True):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        if embs is not None:\n",
    "            embwords, embvecs = embs\n",
    "            logging.info(f\"{len(word2id)} pre-trained word embeddings loaded.\")\n",
    "            if n_d != len(embvecs[0]):\n",
    "                logging.warning(f\"[WARNINGS] n_d ({n_d}) != word vector size ({len(embvecs[0])}). \"\n",
    "                                f\"Use {len(embvecs[0])} for embeddings.\")\n",
    "                n_d = len(embvecs[0])\n",
    "        self.word2id = word2id\n",
    "        self.id2word = {i: word for word, i in word2id.items()}\n",
    "        self.n_V, self.n_d = len(word2id), n_d\n",
    "        self.oovid = word2id[oov]\n",
    "        self.padid = word2id[pad]\n",
    "        # n_V -> n_d, 차원 축소\n",
    "        self.embedding = nn.Embedding(self.n_V, n_d, padding_idx=self.padid)\n",
    "        self.embedding.weight.data.uniform_(-0.25, 0.25)\n",
    "        \n",
    "        if embs is not None:\n",
    "            weight = self.embedding.weight\n",
    "            weight.data[:len(embwords)].copy_(torch.from_numpy(embvecs))\n",
    "            logging.info(\"embedding shape: {}\".format(weight.size()))\n",
    "            \n",
    "        if normalize:\n",
    "            weight = self.embedding.weight\n",
    "            norms = weight.data.norm(2, 1)\n",
    "            if norms.dim() == 1:\n",
    "                norms = norms.unsqueeze(1)\n",
    "            weight.data.div_(norms.expand_as(weight.data))\n",
    "            \n",
    "        if fix_emb:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "            \n",
    "    def forward(self, input_):\n",
    "        return self.embedding(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the model trained with character-based word encoder.\n",
    "if config['token_embedder']['char_dim'] > 0:\n",
    "    char_lexicon = {}\n",
    "    with codecs.open(os.path.join(model_dir, 'char.dic'), 'r', encoding='utf-8') as fpi:\n",
    "        \"\"\"\n",
    "        # char.dic\n",
    "        <\t0\n",
    "        b\t1\n",
    "        ...\n",
    "        특\t18\n",
    "        별\t19\n",
    "        기\t20\n",
    "        고\t21\n",
    "        ...\n",
    "        ữ\t17675\n",
    "        븟\t17676\n",
    "        铸\t17677\n",
    "        鋳\t17678\n",
    "        <bos>\t17679\n",
    "        <eos>\t17680\n",
    "        <oov>\t17681\n",
    "        <pad>\t17682\n",
    "        <bow>\t17683\n",
    "        <eow>\t17684\n",
    "        \"\"\"\n",
    "        for line in fpi:\n",
    "            tokens = line.strip().split('\\t')\n",
    "            if len(tokens) == 1:\n",
    "                tokens.insert(0, '\\u3000')\n",
    "            token, i = tokens\n",
    "            char_lexicon[token] = int(i)\n",
    "    char_emb_layer = EmbeddingLayer(\n",
    "        config['token_embedder']['char_dim'], char_lexicon, fix_emb=False, embs=None)\n",
    "    if use_cuda:\n",
    "        char_emb_layer = char_emb_layer.cuda()\n",
    "    logging.info('char embedding size: ' +\n",
    "                str(len(char_emb_layer.word2id)))\n",
    "else:\n",
    "    char_lexicon = None\n",
    "    char_emb_layer = None\n",
    "\n",
    "# For the model trained with word form word encoder.\n",
    "if config['token_embedder']['word_dim'] > 0:\n",
    "    word_lexicon = {}\n",
    "    with codecs.open(os.path.join(model_dir, 'word.dic'), 'r', encoding='utf-8') as fpi:\n",
    "        \"\"\"\n",
    "        <oov>\t0\n",
    "        <bos>\t1\n",
    "        <eos>\t2\n",
    "        <pad>\t3\n",
    "        ,\t4\n",
    "        .\t5\n",
    "        호텔\t6\n",
    "        ...\n",
    "        (Penobscot\t427840\n",
    "        Tornesch\t427841\n",
    "        Wodociągi\t427842\n",
    "        피트리\t427843\n",
    "        ArmeniaThe\t427844\n",
    "        Cascade에서\t427845\n",
    "        Retrophilia\t427846\n",
    "        kmCala\t427847\n",
    "        노스다코타Dickinson\t427848\n",
    "        \"\"\"\n",
    "        for line in fpi:\n",
    "            tokens = line.strip().split('\\t')\n",
    "            if len(tokens) == 1:\n",
    "                tokens.insert(0, '\\u3000')\n",
    "            token, i = tokens\n",
    "            word_lexicon[token] = int(i)\n",
    "    word_emb_layer = EmbeddingLayer(\n",
    "        config['token_embedder']['word_dim'], word_lexicon, fix_emb=False, embs=None)\n",
    "    if use_cuda:\n",
    "        word_emb_layer = word_emb_layer.cuda()\n",
    "    logging.info('word embedding size: ' +\n",
    "                str(len(word_emb_layer.word2id)))\n",
    "else:\n",
    "    word_lexicon = None\n",
    "    word_emb_layer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingLayer(\n",
       "  (embedding): Embedding(17685, 50, padding_idx=17682)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_emb_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingLayer(\n",
       "  (embedding): Embedding(427849, 100, padding_idx=3)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = word_lexicon\n",
    "char2id = char_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset\n",
    "text = textset\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[2, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "x = test\n",
    "perm = None\n",
    "shuffle = False\n",
    "sort = True\n",
    "\n",
    "ind = list(range(len(x)))\n",
    "lst = perm or ind\n",
    "print(lst)\n",
    "if shuffle:\n",
    "    random.shuffle(lst)\n",
    "    \n",
    "if sort:\n",
    "    lst.sort(key=lambda l: -len(x[l]))\n",
    "    print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<bos>', '유독', '너와', '헤어지다', '싫다', '밤', '집', '으로', '돌아가다', '<eos>'], ['<bos>', '발', '없는', '말이', '천리', '간다', '<eos>'], ['<bos>', '다시', '사랑한다', '말', '할까', '<eos>']]\n",
      "[1, 2, 0]\n",
      "[['유독', '너와', '헤어지다', '싫다', '밤', '집', '으로', '돌아가다'], ['발', '없는', '말이', '천리', '간다'], ['다시', '사랑한다', '말', '할까']]\n"
     ]
    }
   ],
   "source": [
    "x = [x[i] for i in lst]\n",
    "ind = [ind[i] for i in lst]\n",
    "if text is not None:\n",
    "    text = [text[i] for i in lst]\n",
    "\n",
    "print(x)\n",
    "print(ind)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_len = 0.0\n",
    "batches_w, batches_c, batches_lens, batches_masks, batches_text, batches_ind = [], [], [], [], [], []\n",
    "size = batch_size\n",
    "nbatch = (len(x) - 1) // size + 1\n",
    "\n",
    "nbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xec\\x82\\xac\\xeb\\x9e\\x91\\xed\\x95\\x9c\\xeb\\x8b\\xa4'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'사랑한다'.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> : 17679\n",
      "<eos> : 17680\n",
      "<oov> : 17681\n",
      "<pad> : 17682\n",
      "<bow> : 17683\n",
      "<eow> : 17684\n"
     ]
    }
   ],
   "source": [
    "for i in ['<bos>', '<eos>', '<oov>', '<pad>', '<bow>', '<eow>']:\n",
    "    print(f\"{i} : {char2id[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 문장:\n",
      "tensor([[17684, 17679, 17683, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,    87,   416, 17683, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,   183,   223, 17683, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,   478,    27,    76,    92, 17683, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,  1209,    92, 17683, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,  1217, 17683, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,   439, 17683, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,   198,    57, 17683, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,   774,   136,    32,    92, 17683, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684, 17680, 17683, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682]])\n",
      "2번째 문장:\n",
      "tensor([[17684, 17679, 17683, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,   217, 17683, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,   186,    31, 17683, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,   134,    53, 17683, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,   419,    40, 17683, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,    65,    92, 17683, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684, 17680, 17683, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682]])\n",
      "3번째 문장:\n",
      "tensor([[17684, 17679, 17683, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,    92,    42, 17683, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,    43,   580,    59,    92, 17683, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,   134, 17683, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684,   185,    78, 17683, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17684, 17680, 17683, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682],\n",
      "        [17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682,\n",
      "         17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682, 17682]])\n"
     ]
    }
   ],
   "source": [
    "oov='<oov>'\n",
    "pad='<pad>'\n",
    "\n",
    "# Create batch\n",
    "for i in range(nbatch):\n",
    "    start_id, end_id = i * size, (i + 1) * size\n",
    "    # Create one_batch---------------------------------------\n",
    "    x_b = x[start_id: end_id]\n",
    "    batch_size = len(x_b)\n",
    "    lst = list(range(batch_size))\n",
    "    if sort:\n",
    "        lst.sort(key=lambda l: -len(x[l]))\n",
    "    # shuffle the sentences by\n",
    "    x_b = [x_b[i] for i in lst]\n",
    "    lens = [len(x_b[i]) for i in lst]\n",
    "    max_len = max(lens)\n",
    "    \n",
    "    # get a batch of word id whose size is (batch x max_len)\n",
    "    if word2id is not None:\n",
    "        oov_id = word2id.get(oov, None)\n",
    "        pad_id = word2id.get(pad, None)\n",
    "        assert oov_id is not None and pad_id is not None\n",
    "        batch_w = torch.LongTensor(batch_size, max_len).fill_(pad_id)\n",
    "        for i, x_i in enumerate(x_b):\n",
    "            for j, x_ij in enumerate(x_i):\n",
    "                batch_w[i][j] = word2id.get(x_ij, oov_id)\n",
    "    else:\n",
    "        batch_w = None\n",
    "    \n",
    "    # get a batch of character id whose size is (batch x max_chars)\n",
    "    if char2id is not None:\n",
    "        bow_id, eow_id, oov_id, pad_id = [\n",
    "            char2id.get(key, None) \n",
    "            for key in ('<eow>', '<bow>', oov, pad)\n",
    "        ] # 왜 거꾸로 받지???ㄷㄷ;;\n",
    "        assert ((bow_id is not None) and \n",
    "                (eow_id is not None) and\n",
    "                (oov_id is not None) and\n",
    "                (pad_id is not None))\n",
    "        if config['token_embedder']['name'].lower() == 'cnn':\n",
    "            max_chars = config['token_embedder']['max_characters_per_token']\n",
    "            assert max([len(w) for i in lst for w in x_b[i]]) + 2 <= max_chars\n",
    "        elif config['token_embedder']['name'].lower() == 'lstm':\n",
    "            max_chars = max([len(w) for i in lst for w in x_b[i]]) + 2\n",
    "        else:\n",
    "            raise ValueError('Unknown token_embedder: {0}'.format(config['token_embedder']['name']))\n",
    "        batch_c = torch.LongTensor(batch_size, max_len, max_chars).fill_(pad_id)\n",
    "        for i, x_i in enumerate(x_b):\n",
    "            print(f\"{i+1}번째 문장:\")\n",
    "            for j, x_ij in enumerate(x_i):\n",
    "                batch_c[i][j][0] = bow_id\n",
    "                if x_ij in ['<bos>', '<eos>']:\n",
    "                    batch_c[i][j][1] = char2id.get(x_ij)\n",
    "                    batch_c[i][j][2] = eow_id\n",
    "                else:\n",
    "                    for k, c in enumerate(x_ij):\n",
    "                        batch_c[i][j][k+1] = char2id.get(c, oov_id)\n",
    "                    batch_c[i][j][len(x_ij)+1] = eow_id\n",
    "            print(batch_c[i])\n",
    "    else:\n",
    "        batch_c = None\n",
    "        \n",
    "    masks = [torch.LongTensor(batch_size, max_len).fill_(0), [], []]\n",
    "    \n",
    "    for i, x_i in enumerate(x_b):\n",
    "        for j in range(len(x_i)):\n",
    "            masks[0][i][j] = 1\n",
    "            if j + 1 < len(x_i):\n",
    "                masks[1].append(i * max_len + j)\n",
    "            if j > 0:\n",
    "                masks[2].append(i * max_len + j)\n",
    "\n",
    "    assert len(masks[1]) <= batch_size * max_len\n",
    "    assert len(masks[2]) <= batch_size * max_len\n",
    "\n",
    "    masks[1] = torch.LongTensor(masks[1])\n",
    "    masks[2] = torch.LongTensor(masks[2])                            \n",
    "    # -------------------------------------------------------\n",
    "    bw, bc, blens, bmasks = batch_w, batch_c, lens, masks\n",
    "    sum_len += sum(blens)\n",
    "    batches_w.append(bw)\n",
    "    batches_c.append(bc)\n",
    "    batches_lens.append(blens)\n",
    "    batches_masks.append(bmasks)\n",
    "    batches_ind.append(ind[start_id: end_id])\n",
    "    if text is not None:\n",
    "        batches_text.append(text[start_id: end_id])\n",
    "        \n",
    "if sort:\n",
    "    perm = list(range(nbatch))\n",
    "    random.shuffle(perm)\n",
    "    batches_w = [batches_w[i] for i in perm]\n",
    "    batches_c = [batches_c[i] for i in perm]\n",
    "    batches_lens = [batches_lens[i] for i in perm]\n",
    "    batches_masks = [batches_masks[i] for i in perm]\n",
    "    batches_ind = [batches_ind[i] for i in perm]\n",
    "    if text is not None:\n",
    "        batches_text = [batches_text[i] for i in perm]\n",
    "\n",
    "logging.info(\"{} batches, avg len: {:.1f}\".format(\n",
    "    nbatch, sum_len / len(x)))\n",
    "recover_ind = [item for sublist in batches_ind for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[     1,  36081,  26437,      0,  65226,   1973,   2607,   3650,      0,\n",
       "               2],\n",
       "         [     1,   1820,    325,   3232, 345792,   7127,      2,      3,      3,\n",
       "               3],\n",
       "         [     1,    237,  50660,   1489,  13000,      2,      3,      3,      3,\n",
       "               3]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[17684, 17679, 17683,  ..., 17682, 17682, 17682],\n",
       "          [17684,    87,   416,  ..., 17682, 17682, 17682],\n",
       "          [17684,   183,   223,  ..., 17682, 17682, 17682],\n",
       "          ...,\n",
       "          [17684,   198,    57,  ..., 17682, 17682, 17682],\n",
       "          [17684,   774,   136,  ..., 17682, 17682, 17682],\n",
       "          [17684, 17680, 17683,  ..., 17682, 17682, 17682]],\n",
       " \n",
       "         [[17684, 17679, 17683,  ..., 17682, 17682, 17682],\n",
       "          [17684,   217, 17683,  ..., 17682, 17682, 17682],\n",
       "          [17684,   186,    31,  ..., 17682, 17682, 17682],\n",
       "          ...,\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682]],\n",
       " \n",
       "         [[17684, 17679, 17683,  ..., 17682, 17682, 17682],\n",
       "          [17684,    92,    42,  ..., 17682, 17682, 17682],\n",
       "          [17684,    43,   580,  ..., 17682, 17682, 17682],\n",
       "          ...,\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682]]])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 7, 6]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]),\n",
       "  tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 20, 21, 22,\n",
       "          23, 24]),\n",
       "  tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 13, 14, 15, 16, 21, 22, 23,\n",
       "          24, 25])]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['유독', '너와', '헤어지다', '싫다', '밤', '집', '으로', '돌아가다'],\n",
       "  ['발', '없는', '말이', '천리', '간다'],\n",
       "  ['다시', '사랑한다', '말', '할까']]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recover_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    batches_w[0] = batches_w[0].cuda()\n",
    "    batches_c[0] = batches_c[0].cuda()\n",
    "    batches_masks[0] = [mask.cuda() for mask in batches_masks[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[     1,  36081,  26437,      0,  65226,   1973,   2607,   3650,      0,\n",
       "               2],\n",
       "         [     1,   1820,    325,   3232, 345792,   7127,      2,      3,      3,\n",
       "               3],\n",
       "         [     1,    237,  50660,   1489,  13000,      2,      3,      3,      3,\n",
       "               3]], device='cuda:0')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[17684, 17679, 17683,  ..., 17682, 17682, 17682],\n",
       "          [17684,    87,   416,  ..., 17682, 17682, 17682],\n",
       "          [17684,   183,   223,  ..., 17682, 17682, 17682],\n",
       "          ...,\n",
       "          [17684,   198,    57,  ..., 17682, 17682, 17682],\n",
       "          [17684,   774,   136,  ..., 17682, 17682, 17682],\n",
       "          [17684, 17680, 17683,  ..., 17682, 17682, 17682]],\n",
       " \n",
       "         [[17684, 17679, 17683,  ..., 17682, 17682, 17682],\n",
       "          [17684,   217, 17683,  ..., 17682, 17682, 17682],\n",
       "          [17684,   186,    31,  ..., 17682, 17682, 17682],\n",
       "          ...,\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682]],\n",
       " \n",
       "         [[17684, 17679, 17683,  ..., 17682, 17682, 17682],\n",
       "          [17684,    92,    42,  ..., 17682, 17682, 17682],\n",
       "          [17684,    43,   580,  ..., 17682, 17682, 17682],\n",
       "          ...,\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "          [17682, 17682, 17682,  ..., 17682, 17682, 17682]]], device='cuda:0')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]], device='cuda:0'),\n",
       "  tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 20, 21, 22,\n",
       "          23, 24], device='cuda:0'),\n",
       "  tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 13, 14, 15, 16, 21, 22, 23,\n",
       "          24, 25], device='cuda:0')]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이어서 계속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_w, test_c, test_lens, test_masks, test_text, recover_ind = (\n",
    "    batches_w, batches_c, batches_lens, batches_masks, batches_text, recover_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, c, lens, masks, texts = next(zip(test_w, test_c, test_lens, test_masks, test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output = self.model.forward(w, c, masks)\n",
    "# token_embedder = ConvTokenEmbedder(\n",
    "#     config, word_emb_layer, char_emb_layer, use_cuda)\n",
    "\n",
    "emb_dim = 0\n",
    "output_dim = config['encoder']['projection_dim']\n",
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if word_emb_layer is not None:\n",
    "    emb_dim += word_emb_layer.n_d\n",
    "emb_dim    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'cnn',\n",
       " 'activation': 'relu',\n",
       " 'filters': [[1, 32],\n",
       "  [2, 32],\n",
       "  [3, 64],\n",
       "  [4, 128],\n",
       "  [5, 256],\n",
       "  [6, 512],\n",
       "  [7, 1024]],\n",
       " 'n_highway': 2,\n",
       " 'word_dim': 100,\n",
       " 'char_dim': 50,\n",
       " 'max_characters_per_token': 50}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['token_embedder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = config['token_embedder']['filters']\n",
    "char_embed_dim = config['token_embedder']['char_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutions = []\n",
    "\n",
    "for i, (width, num) in enumerate(filters):\n",
    "    conv = nn.Conv1d(\n",
    "        in_channels=char_embed_dim,\n",
    "        out_channels=num, # 문자를 몇 개나 볼 것인지\n",
    "        kernel_size=width,\n",
    "        bias=True\n",
    "    )\n",
    "    if use_cuda:\n",
    "        conv = conv.cuda()\n",
    "    convolutions.append(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv1d(50, 32, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(50, 32, kernel_size=(2,), stride=(1,)),\n",
       " Conv1d(50, 64, kernel_size=(3,), stride=(1,)),\n",
       " Conv1d(50, 128, kernel_size=(4,), stride=(1,)),\n",
       " Conv1d(50, 256, kernel_size=(5,), stride=(1,)),\n",
       " Conv1d(50, 512, kernel_size=(6,), stride=(1,)),\n",
       " Conv1d(50, 1024, kernel_size=(7,), stride=(1,))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
       "  (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
       "  (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
       "  (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
       "  (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
       "  (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
       "  (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolutions = nn.ModuleList(convolutions)\n",
    "convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_filters = sum(f[1] for f in filters)\n",
    "n_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_highway = config['token_embedder']['n_highway']\n",
    "n_highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Highway(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 num_layers: int = 1,\n",
    "                 activation: Callable[[torch.Tensor], torch.Tensor] = torch.nn.functional.relu) -> None:\n",
    "        super(Highway, self).__init__()\n",
    "        self._input_dim = input_dim\n",
    "        self._layers = nn.ModuleList(\n",
    "            [nn.Linear(input_dim, input_dim * 2).cuda() if use_cuda \n",
    "             else nn.Linear(input_dim, input_dim * 2).cuda()\n",
    "             for _ in range(num_layers)])\n",
    "        self._activation = activation\n",
    "        for layer in self._layers:\n",
    "            # We should bias the highway layer to just carry its input forward.  We do that by\n",
    "            # setting the bias on `B(x)` to be positive, because that means `g` will be biased to\n",
    "            # be high, to we will carry the input forward.  The bias on `B(x)` is the second half\n",
    "            # of the bias vector in each Linear layer.\n",
    "            layer.bias[input_dim:].data.fill_(1)\n",
    "        \n",
    "    @overrides\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:  # pylint: disable=arguments-differ\n",
    "        current_input = inputs\n",
    "        for layer in self._layers:\n",
    "            projected_input = layer(current_input)\n",
    "            linear_part = current_input\n",
    "            # NOTE: if you modify this, think about whether you should modify the initialization\n",
    "            # above, too.\n",
    "            nonlinear_part = projected_input[:, (0 * self._input_dim):(1 * self._input_dim)]\n",
    "            gate = projected_input[:, (1 * self._input_dim):(2 * self._input_dim)]\n",
    "            nonlinear_part = self._activation(nonlinear_part)\n",
    "            gate = torch.sigmoid(gate)\n",
    "            current_input = gate * linear_part + (1 - gate) * nonlinear_part\n",
    "        return current_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "highways = Highway(n_filters, n_highway, torch.nn.functional.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2148"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim += n_filters\n",
    "emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = nn.Linear(emb_dim, output_dim, bias=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.forward(w, c, masks)\n",
    "# token_embedder.forward()\n",
    "\n",
    "word_inp = w\n",
    "\n",
    "chars_package = c\n",
    "chars_inp = chars_package\n",
    "\n",
    "mask_package = masks\n",
    "shape = mask_package[0].size(0), mask_package[0].size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     1,  36081,  26437,      0,  65226,   1973,   2607,   3650,      0,\n",
       "              2],\n",
       "        [     1,   1820,    325,   3232, 345792,   7127,      2,      3,      3,\n",
       "              3],\n",
       "        [     1,    237,  50660,   1489,  13000,      2,      3,      3,      3,\n",
       "              3]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[17684, 17679, 17683,  ..., 17682, 17682, 17682],\n",
       "         [17684,    87,   416,  ..., 17682, 17682, 17682],\n",
       "         [17684,   183,   223,  ..., 17682, 17682, 17682],\n",
       "         ...,\n",
       "         [17684,   198,    57,  ..., 17682, 17682, 17682],\n",
       "         [17684,   774,   136,  ..., 17682, 17682, 17682],\n",
       "         [17684, 17680, 17683,  ..., 17682, 17682, 17682]],\n",
       "\n",
       "        [[17684, 17679, 17683,  ..., 17682, 17682, 17682],\n",
       "         [17684,   217, 17683,  ..., 17682, 17682, 17682],\n",
       "         [17684,   186,    31,  ..., 17682, 17682, 17682],\n",
       "         ...,\n",
       "         [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "         [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "         [17682, 17682, 17682,  ..., 17682, 17682, 17682]],\n",
       "\n",
       "        [[17684, 17679, 17683,  ..., 17682, 17682, 17682],\n",
       "         [17684,    92,    42,  ..., 17682, 17682, 17682],\n",
       "         [17684,    43,   580,  ..., 17682, 17682, 17682],\n",
       "         ...,\n",
       "         [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "         [17682, 17682, 17682,  ..., 17682, 17682, 17682],\n",
       "         [17682, 17682, 17682,  ..., 17682, 17682, 17682]]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = []\n",
    "batch_size, seq_len = shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-0.0508, -0.0216, -0.1654,  ...,  0.1214, -0.1172,  0.1733],\n",
       "          [ 0.0709, -0.1222,  0.0280,  ..., -0.1042,  0.0624, -0.0978],\n",
       "          [ 0.1251, -0.1699,  0.0665,  ...,  0.1185,  0.0900, -0.1325],\n",
       "          ...,\n",
       "          [-0.0291,  0.0696,  0.0685,  ...,  0.0830, -0.1760, -0.1166],\n",
       "          [ 0.0955,  0.0539,  0.0060,  ..., -0.1611, -0.1156, -0.0937],\n",
       "          [ 0.0137, -0.0109, -0.0076,  ..., -0.1306,  0.0119, -0.0906]],\n",
       " \n",
       "         [[-0.0508, -0.0216, -0.1654,  ...,  0.1214, -0.1172,  0.1733],\n",
       "          [-0.0820,  0.1113, -0.1338,  ...,  0.1058,  0.1346, -0.1351],\n",
       "          [ 0.0746,  0.0447,  0.0461,  ..., -0.1356, -0.0233, -0.1438],\n",
       "          ...,\n",
       "          [ 0.1253, -0.1006, -0.1339,  ...,  0.1198,  0.0417,  0.1092],\n",
       "          [ 0.1253, -0.1006, -0.1339,  ...,  0.1198,  0.0417,  0.1092],\n",
       "          [ 0.1253, -0.1006, -0.1339,  ...,  0.1198,  0.0417,  0.1092]],\n",
       " \n",
       "         [[-0.0508, -0.0216, -0.1654,  ...,  0.1214, -0.1172,  0.1733],\n",
       "          [ 0.1390,  0.0992,  0.1660,  ...,  0.1480,  0.0138,  0.0086],\n",
       "          [ 0.0705,  0.1265, -0.1422,  ...,  0.0288, -0.0428,  0.1308],\n",
       "          ...,\n",
       "          [ 0.1253, -0.1006, -0.1339,  ...,  0.1198,  0.0417,  0.1092],\n",
       "          [ 0.1253, -0.1006, -0.1339,  ...,  0.1198,  0.0417,  0.1092],\n",
       "          [ 0.1253, -0.1006, -0.1339,  ...,  0.1198,  0.0417,  0.1092]]],\n",
       "        device='cuda:0', grad_fn=<EmbeddingBackward>)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if word_emb_layer is not None:\n",
    "    batch_size, seq_len = word_inp.size()\n",
    "    variable = Variable(word_inp)\n",
    "    if use_cuda:\n",
    "        variable = variable.cuda()\n",
    "    word_emb = word_emb_layer(variable)\n",
    "    embs.append(word_emb)\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 100])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_emb_layer is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 50])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 50])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_inp = chars_inp.view(batch_size * seq_len, -1)\n",
    "chars_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(17685, 50, padding_idx=17682)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_emb_layer.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_embedding = char_emb_layer(\n",
    "    Variable(chars_inp).cuda() if use_cuda\n",
    "    else Variable(chars_inp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 50, 50])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 50, 50])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_embedding = torch.transpose(character_embedding, 1, 2)\n",
    "character_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = getattr(torch.nn.functional, \n",
    "                     config['token_embedder']['activation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(convolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved = convolutions[i](character_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 32, 50])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolved.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved = torch.max(convolved, dim=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 32])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolved.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved = activation(convolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs.append(convolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([30, 32, 49])\n",
      "torch.Size([30, 32])\n",
      "torch.Size([30, 32])\n",
      "2\n",
      "torch.Size([30, 64, 48])\n",
      "torch.Size([30, 64])\n",
      "torch.Size([30, 64])\n",
      "3\n",
      "torch.Size([30, 128, 47])\n",
      "torch.Size([30, 128])\n",
      "torch.Size([30, 128])\n",
      "4\n",
      "torch.Size([30, 256, 46])\n",
      "torch.Size([30, 256])\n",
      "torch.Size([30, 256])\n",
      "5\n",
      "torch.Size([30, 512, 45])\n",
      "torch.Size([30, 512])\n",
      "torch.Size([30, 512])\n",
      "6\n",
      "torch.Size([30, 1024, 44])\n",
      "torch.Size([30, 1024])\n",
      "torch.Size([30, 1024])\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(convolutions)):\n",
    "    print(i)\n",
    "    convolved = convolutions[i](character_embedding)\n",
    "    print(convolved.shape)\n",
    "    convolved = torch.max(convolved, dim=-1)[0]\n",
    "    print(convolved.shape)\n",
    "    convolved = activation(convolved)\n",
    "    print(convolved.shape)\n",
    "    convs.append(convolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([30, 32]),\n",
       " torch.Size([30, 32]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([30, 128]),\n",
       " torch.Size([30, 256]),\n",
       " torch.Size([30, 512]),\n",
       " torch.Size([30, 1024])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[conv.shape for conv in convs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2048])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_emb = torch.cat(convs, dim=-1)\n",
    "char_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2048])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_emb = highways(char_emb)\n",
    "char_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 2048])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_emb_ = char_emb.view(batch_size, -1, n_filters)\n",
    "chat_emb_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.append(chat_emb_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 10, 100]), torch.Size([3, 10, 2048]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0].shape, embs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 2148])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding = torch.cat(embs, dim=2)\n",
    "token_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 512])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding = projection(token_embedding)\n",
    "token_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0390, -0.0220, -0.0156,  ..., -0.0217,  0.0428,  0.0218],\n",
       "         [ 0.0241,  0.0135,  0.0016,  ..., -0.0051,  0.0588,  0.0087],\n",
       "         [ 0.0541,  0.0214, -0.0041,  ..., -0.0126,  0.0095,  0.0096],\n",
       "         ...,\n",
       "         [ 0.0218, -0.0157,  0.0076,  ..., -0.0510,  0.0284, -0.0066],\n",
       "         [ 0.0099,  0.0162, -0.0203,  ..., -0.0051,  0.0396,  0.0394],\n",
       "         [ 0.0377,  0.0068, -0.0379,  ..., -0.0172,  0.0191,  0.0216]],\n",
       "\n",
       "        [[ 0.0390, -0.0220, -0.0156,  ..., -0.0217,  0.0428,  0.0218],\n",
       "         [ 0.0519,  0.0240, -0.0371,  ..., -0.0200,  0.0169,  0.0107],\n",
       "         [ 0.0087, -0.0087, -0.0147,  ..., -0.0115,  0.0325,  0.0461],\n",
       "         ...,\n",
       "         [ 0.0363,  0.0190, -0.0178,  ..., -0.0411,  0.0160,  0.0197],\n",
       "         [ 0.0363,  0.0190, -0.0178,  ..., -0.0411,  0.0160,  0.0197],\n",
       "         [ 0.0363,  0.0190, -0.0178,  ..., -0.0411,  0.0160,  0.0197]],\n",
       "\n",
       "        [[ 0.0390, -0.0220, -0.0156,  ..., -0.0217,  0.0428,  0.0218],\n",
       "         [ 0.0650,  0.0255, -0.0312,  ..., -0.0264, -0.0280,  0.0286],\n",
       "         [ 0.0314,  0.0331, -0.0254,  ...,  0.0050,  0.0482,  0.0054],\n",
       "         ...,\n",
       "         [ 0.0363,  0.0190, -0.0178,  ..., -0.0411,  0.0160,  0.0197],\n",
       "         [ 0.0363,  0.0190, -0.0178,  ..., -0.0411,  0.0160,  0.0197],\n",
       "         [ 0.0363,  0.0190, -0.0178,  ..., -0.0411,  0.0160,  0.0197]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이어서 계속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]], device='cuda:0'),\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 20, 21, 22,\n",
       "         23, 24], device='cuda:0'),\n",
       " tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 13, 14, 15, 16, 21, 22, 23,\n",
       "         24, 25], device='cuda:0')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = Variable(mask_package[0]).cuda()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules.elmo.py\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import PackedSequence, pad_packed_sequence, pack_padded_sequence\n",
    "from torch.autograd import Variable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
